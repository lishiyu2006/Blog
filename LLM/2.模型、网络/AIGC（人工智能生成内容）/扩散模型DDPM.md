# 扩散模型DDPM
## 结构：级联去噪模型
## 前提
1.任何一张图像 x（无论是 x_0, x_t 还是噪声 ε）都会被转换成一个张量。
一个典型的图像张量包含以下维度信息：

**(Batch Size, Channels, Height, Width)**

- **Batch Size (B)**：一批处理多少张图片。在训练时通常大于1（如16, 32），在生成单张图时为1。
    
- **Channels (C)**：颜色通道。
    - 对于彩色图（RGB），Channels = 3。
    - 对于灰度图，Channels = 1。
        
- **Height (H)**：图像的高度（像素数）。
    
- **Width (W)**：图像的宽度（像素数）。 

2.1) $q$ 通常用来表示一个**预先定义好的、固定的、不需要学习**的概率分布。它代表了某种“事实”或“数学真理”。例如:
$q(x_t | x_{t-1})$ (前向过程)
$q(x_{t-1} | x_t, x_0)$ (真实的逆向过程 - 条件)
$q(x_{t-1} | x_t)$ (真实的逆向过程 - 无条件)

2.2) $p$ (通常带有下标 $θ$) 用来表示一个**由神经网络定义的、需要通过训练学习**的概率分布。它是一个**近似模型**。例如:
$p_θ(x_{t-1} | x_t)$ (学习的逆向过程)


## 步骤：
## 一.前向过程
 **前向扩散**:前向过程是加噪的过程，前向过程中图像 $x_t$ 只和上一时刻的 $x_{t-1}$ 有关, 该过程可以视为[马尔可夫链](https://zhuanlan.zhihu.com/p/448575579)![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202509291011820.png)
### 微观：
首先推出 $x_t$ 和 $x_{t-1}$ 的关系是：
$x_t = \sqrt{α_t} * x_{t-1} + \sqrt{1 - α_t} * ε_{t-1}$
因为是一个马尔科夫过程，所以最后都会归为一个稳定的状态，由此推断 $x_0$ 和 $x_t$ 也与一个稳定的公式，验证得到：
$x_t = \sqrt{\bar{α}_t} * x_0 + \sqrt{1 - \bar{α}_t} * ε$
**参数解释**：
1. $x_0$ (原始图像)
    - **是什么**：这是你的“基酒”，是清晰、无噪声的原始图片（比如一张猫的照片）。
        
2.  $\epsilon_t$ (噪声)
    - **是什么**：这是“调味剂”，是一个从标准正态分布（高斯噪声）中随机抽取的、和 x_0 尺寸完全相同的噪声张量。
    - **怎么得到**：
		- 噪声是从标准高斯分布（正态分布$ε ~ N(0, 1)$）中随机采样的，类似“随机抽数”。
		- 高斯分布是一种常见的数据分布（如身高、成绩的分布），从中采样能得到符合“自然随机性”的数值。
		
3. $\sqrt{\bar{α}_t}$ (图像权重)
    - **是什么**：这是“基酒”的**份量**。这个值由时间步 t 和预设的 Beta Schedule 共同决定。
    - **规律**：
        - 当 t 很小（刚开始加噪）时，$\bar{α}_t$ 接近 1，所以这个权重也接近 1。
        - 当 t 很大（接近纯噪声）时，$\bar{α}_t$ 近 0，所以这个权重也接近 0。
    - **怎么得到**： 
        - 系数是人工预设的固定值，非模型学习而来，目的是让加噪过程平稳可控。
        - 先设定一个微小的“每步噪声强度” $\beta_t$（如0.001~0.02），$\beta_t$ 可固定或随步数轻微增大。
        - 计算关系：$\alpha_t = 1 - \beta_t$，再通过累积得到 $\bar{\alpha}_t = \prod_{i=1}^{t} \alpha_i$（用于简化前向计算）。
        - 其中 $\beta_t$ 怎么算：
	        - 当前图像 $x_t$ 的条件概率分布，这是一个高斯分布，其均值为 $\sqrt{1-\beta_t}x_{t-1}$ ，方差为 $\beta_t$ ，其中 $\beta_t$ 是一个预定的噪声方差系数，$I$ 是单位矩阵。
	        - 其中不同 $t$ 的 $\beta_t$ 是预先定义好的，由时间 $1$~$T$ 逐渐的递增，可以是Linear，Cosine等，满足 : $β_1 < β_2 < ... < β_T$。
            
4. $\sqrt{1 - \bar{α}_t}$ (噪声权重)
    - **是什么**：这是“调味剂”（噪声）的**份量**。
    - **规律**：     
        - 当 t 很小的时候，这个权重接近 0。
        - 当 t 很大的时候，这个权重接近 1。

### 宏观：
前向过程的图像 $x_t$ 值和上一时刻的 $x_{t-1}$ 有关，他们之间的关系可以表示成一个多维高斯分布（条件概率），它不是描述一个单一数值的概率，而是描述一个包含成千上万个数值的**向量**的概率：
$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t}x_{t-1}, \beta_t I)$
每一步 $q(x_t|x_{t-1})$ 表示:第 $t$ 步的噪声图像 $x_t$ ，是通过将第 $t-1$ 步的图像 $x_{t-1}$ 的像素值稍微缩小一点，然后给每个像素独立地添加一个强度为 $\beta_t$ 的[高斯噪声](../../高斯噪声.md)得到的。
因为他是一个 [马尔可夫链](https://zhuanlan.zhihu.com/p/448575579) ，所以得出最后的稳定关系是这个关系：
$q(x_{1:T}|x_0) = \prod_{t=1}^{T} q(x_t|x_{t-1})$ 
eg.一维高斯分布
![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202509291633054.png)
二维高斯分布
![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202509291632813.png)
多维...
## 二.逆向过程

 **反向去噪**:逆向过程是去噪的过程，如果得到好的逆向过程就可以通过随机噪声 逐步还原出一张图像。DDPM使用神经网络拟合逆向过程。![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202509262221782.png)
attention：
1.无论是前向过程还是反向过程都是一个参数化的[马尔可夫链](https://zhuanlan.zhihu.com/p/448575579)（Markov chain）（即当经过一定的训练负责还原或者加噪1%的这部分会最终稳定下来），其中反向过程可用于生成数据样本（它的作用类似GAN中的生成器，只不过GAN生成器会有维度变化，而DDPM的反向过程没有维度变化）








逆向过程是去噪的过程,如果得到逆向过程 $q(x_{t-1}|x_t)$ ，就可以通过随机噪声 逐步还原出一张图像。DDPM使用神经网络  拟合逆向过程  。
$q(x_{t-1}|x_t, x_0) = N(x_{t-1} | \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I)$ ,可以推导出:
$p_θ(x_{t-1}|x_t) = N(x_{t-1} | \mu_θ(x_t, t), Σ_θ(x_t, t))$

这里的均值 $\tilde{\mu}_t$ 和方差 $\tilde{\beta}_t$ 是属于**逆向过程后验分布**（reverse process posterior）的参数，它们是通过数学推导得出的“真实”去噪步骤的参数，而不是我们之前在前向（加噪）过程中定义的原始参数 $β_t$。

|      | 第一行                            | 第二行                            |
| ---- | ------------------------------ | ------------------------------ |
| 角色   | 标准答案 **(Ground Truth)**        | 学生的回答 **(Model's Prediction)** |
| 前提条件 | 知道问题 $(x_t)$ 和答案 $(x_0)$       | 只知道问题 $(x_t)$                  |
| 均值   | $\tilde{\mu}_t$ (波浪号): 真实的均值   | $\mu_θ$: 预测的均值                 |
| 方差   | $\tilde{\beta}_t$ (波浪号): 真实的方差 | $Σ_θ$: 预测的方差                   |

DDPM 论文中通过神经网络（通常是 U-Net）拟合噪声预测模型 $ε_θ$ ，从而间接得到均值 $\mu_θ$​，以计算 $x_{t-1}$ 。方差通常是固定的，并未直接通过神经网络拟合，而是由扩散过程的参数决定。
$μ_θ = (1 / sqrt(α_t)) * (x_t - ((1 - α_t) / sqrt(1 - ᾱ_t)) * ε_θ(x_t, t))$

### 可以使用的神经网络：U-Net，Transformer
这里采用Unet实现正向的预测，整个训练过程其实就是在训练Unet网络的参数