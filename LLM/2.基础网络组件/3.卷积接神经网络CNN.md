# 卷积接神经网络CNN
## 一、原理
图像在计算机中是一堆按顺序排列的数字，数值为0到255。0表示最暗，255表示最亮。

照片有灰度模式，直接一个矩阵表示即可，而更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维张量去理解。

其中的每一个矩阵又叫这个图片的一个channel（通道），宽, 高, 深来描述。

![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510081559415.png)

### 为什么要学习卷积神经网络？

在传统神经网络中，我们要识别下图红色框中的图像时，我们很可能识别不出来，因为这六张图的特征位置都不通，计算机无法分辨出他们其实是一种形状或物体。

我们希望一个物体不管在画面左侧还是右侧，都会被识别为同一物体，这一特点就是不变性。为了实现平移不变性，卷积神经网络（CNN）等深度学习模型在卷积层中使用了卷积操作，这个操作可以捕捉到图像中的局部特征而不受其位置的影响。

## 二、什么是卷积？
在卷积神经网络中，卷积操作是指将一个可移动的小窗口（称为数据窗口，如下图绿色矩形）与图像进行逐元素相乘然后相加的操作。这个小窗口其实是一组固定的权重，它可以被看作是一个特定的滤波器（filter）或卷积核。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。这一操作是卷积神经网络名字的来源。

这张图中蓝色的框就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）

![](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510081614281.png)

### 卷积计算过程：

![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510081628167.png)

#### 1. 感受野(Receptive Field)

#### (1) 什么是感受野

感受野指的是卷积神经网络每一层输出的特征图(feature map)上每个像素点映射回输入图像上的区域大小。

神经元感受野的范围越大表示其能接触到的原始图像范围就越大，也意味着它能学习更为全局，语义层次更高的特征信息；相反，范围越小则表示其所包含的特征越趋向局部和细节。

由此可知，深度卷积神经网络中靠前的层感受野较小，提取到的是图像的纹理、边缘等局部的、通用的特征；靠后的层由于感受野较大，提取到的是图像更深层次、更具象的特征。因此在迁移学习中常常会将靠前的层的参数冻结（不参与训练，因为他们在迁移到新的场景之前已经具备了提取通用特征的能力），来节省训练的时间和算力消耗。

首先回顾一下从输入特征图到输出特征图尺寸的计算公式（其中$n_{in}$为输入size，$p$为padding大小，$f$为卷积核size，$s$为卷积步长）：
padding是卷积核的大小
在卷积操作中，卷积核会按照一定的 “步长” 在输入特征图上滑动，每次滑动后与对应区域进行元素相乘再求和，生成输出特征图上的一个像素。

![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510082136564.png)

假设输入大小为5×5，f=3×3，padding为1×1，卷积步长为2×2，那么输出特征图size根据公式可计算为3×3。  
下面给出感受野的计算公式：

![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510082148183.png)

其中$RF_{l+1}$为当前特征图对应的感受野大小，也就是我们要计算的目标感受野，$RF_l$为上一层特征图对应的感受野大小，$f_{l+1}$为当前卷积层卷积核大小，最后一项连乘项则表示之前卷积层的步长乘积。

卷积需要注意哪些问题？
a.步长stride：每次滑动的位置步长。

b. 卷积核的个数：决定输出的depth厚度。同时代表卷积核的个数。

c. 填充值zero-padding：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。

以上图为例，那么：

• 数据窗口每次移动两个步长取 3*3 的局部数据，即 stride=2 。
• 两个神经元，即 depth=2 ，意味着有两个滤波器。
• zero-padding=1 。

### 为什么要填充?

因为边缘特征卷积以后保留不下来

## 三、卷积神经网络的构造
![image.png](https://raw.githubusercontent.com/lishiyu2006/picgo/main/cdning/202510081651752.png)
1 输入层
输入层接收原始图像数据。图像通常由三个颜色通道（红、绿、蓝）组成，形成一个二维矩阵，表示像素的强度值。

2 卷积和激活
卷积层将输入图像与卷积核进行卷积操作。然后，通过应用激活函数（如ReLU）来引入非线性。这一步使网络能够学习复杂的特征。

3 池化层
池化层通过减小特征图的大小来减少计算复杂性。它通过选择池化窗口内的最大值或平均值来实现。这有助于提取最重要的特征。

4 多层堆叠
CNN通常由多个卷积和池化层的堆叠组成，以逐渐提取更高级别的特征。深层次的特征可以表示更复杂的模式。

5 全连接和输出
最后，全连接层将提取的特征映射转化为网络的最终输出。这可以是一个分类标签、回归值或其他任务的结果。

